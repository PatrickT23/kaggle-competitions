{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Digit Recogniser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \tIntroduction\n",
    "\n",
    "This is my attempt the 'Digit Recogniser' challenge in Kaggle (link is here: https://www.kaggle.com/c/digit-recognizer/overview). Using my knowledge on CNNs and advice from other kernels submitted over time I have created this Python Notebook running through a neural network to recognise digits (0-9) from handwritten images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries\n",
    "\n",
    "First step is to import the relevant libraries for use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The first step is to import and prepare the data. Thankfully this data is quite clean and so only need minimal transformation is required. One important part to note is the normalisation of the data to allow the CNN model to converge better, redsucing the effects of the pixel intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('./data/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels as the Y values\n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column and make this the X values\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 42000 rows\n"
     ]
    }
   ],
   "source": [
    "# Here we should get the shape of the data and understand the dimensions\n",
    "print(\"The data has \" + str(X_train.shape[0]) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the label data\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 1234\n",
    "# Split the train and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAg/kBThB5Ii/EBShB9I6v8BIdCsNK6tjIUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2d8b20f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we will plot one of the images as an example to show what it looks like\n",
    "g = plt.imshow(X_train[100][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "\n",
    "Here we will set up our Neural Network model, using a 32 filters in the first 2 Conv2D layers and 64 filters in the last 2 Conv2D layers. Throughout this process we also involve Max Pooling, Batch Normalisation and Flattening and finally to ensure we get our 10 classes we add the 'Dense' and use a softmax.\n",
    "\n",
    "What is also pivotal here is to augment the data before training it which was important to ensure we don't over fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all the model paramters up now\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer up\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "# Define the number of epochs (only used 2 here but can use a lot more)\n",
    "epochs = 2 \n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally augment the data as well\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "CNN_model = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Test\n",
    "\n",
    "Now we can run the model with the test data and upload it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# Select the value with the highest probability\n",
    "results = np.argmax(results,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert the results to a format we can upload to Kaggle\n",
    "results = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "results.to_csv(\"./output/results.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
